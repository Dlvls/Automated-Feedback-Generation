{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCnX11iAEMB2",
        "outputId": "cbe9f2b0-c532-4ff7-cc99-610857ed034e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import cohen_kappa_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "clOH2FEeFCs-"
      },
      "outputs": [],
      "source": [
        "sao = pd.read_csv(\"sao_rubrics.csv\")\n",
        "ca = pd.read_csv(\"ca_rubrics.csv\")\n",
        "gas = pd.read_csv(\"gas_rubrics.csv\")\n",
        "cor = pd.read_csv(\"cor_rubrics.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iEXTVpmEFD6x"
      },
      "outputs": [],
      "source": [
        "y_sao = sao['word_count_score']\n",
        "X_sao = sao[['esai', 'word_count']]\n",
        "\n",
        "y_ca = ca['noun_count_score']\n",
        "X_ca = ca[['esai', 'noun_count']]\n",
        "\n",
        "y_gas = gas['spell_error_count_final_score']\n",
        "X_gas = gas[['esai', 'spell_error_count']]\n",
        "\n",
        "y_cor = cor['final_score'].iloc[:12934]\n",
        "X_cor = cor[['essay']].iloc[:12934]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "150Wi7vGWjlS",
        "outputId": "62fb1b08-66b9-4594-f140-8917d2a808e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12934,)\n",
            "(12934,)\n",
            "(12934,)\n",
            "(12934,)\n"
          ]
        }
      ],
      "source": [
        "print(y_sao.shape)\n",
        "print(y_ca.shape)\n",
        "print(y_gas.shape)\n",
        "print(y_cor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2a1GG8dIIbQ3"
      },
      "outputs": [],
      "source": [
        "X_sao_train, X_sao_test, X_ca_train, X_ca_test, X_gas_train, X_gas_test, X_cor_train, X_cor_test, y_sao_train, y_sao_test, y_ca_train, y_ca_test, y_gas_train, y_gas_test, y_cor_train, y_cor_test = train_test_split(X_sao, X_ca, X_gas, X_cor, y_sao, y_ca, y_gas, y_cor, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z6Sm8UEMFJga"
      },
      "outputs": [],
      "source": [
        "train_e_sao = X_sao_train['esai'].tolist()\n",
        "test_e_sao = X_sao_test['esai'].tolist()\n",
        "\n",
        "train_e_ca = X_ca_train['esai'].tolist()\n",
        "test_e_ca = X_ca_test['esai'].tolist()\n",
        "\n",
        "train_e_gas = X_gas_train['esai'].tolist()\n",
        "test_e_gas = X_gas_test['esai'].tolist()\n",
        "\n",
        "train_e_cor = X_cor_train['essay'].tolist()\n",
        "test_e_cor = X_cor_test['essay'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-HcEKoCzFLGN"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def sent2word(x):\n",
        "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
        "    x.lower()\n",
        "    filtered_sentence = []\n",
        "    words=x.split()\n",
        "    for w in words:\n",
        "        if w not in stop_words:\n",
        "            filtered_sentence.append(w)\n",
        "    return filtered_sentence\n",
        "\n",
        "def essay2word(essay):\n",
        "    essay = essay.strip()\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw = tokenizer.tokenize(essay)\n",
        "    final_words=[]\n",
        "    for i in raw:\n",
        "        if(len(i)>0):\n",
        "            final_words.append(sent2word(i))\n",
        "    return final_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Sg68aq24X1op"
      },
      "outputs": [],
      "source": [
        "# Processing 'esai' for sao task\n",
        "train_sents_sao = []\n",
        "test_sents_sao = []\n",
        "\n",
        "for i in train_e_sao:\n",
        "    train_sents_sao += essay2word(i)\n",
        "\n",
        "for i in test_e_sao:\n",
        "    test_sents_sao += essay2word(i)\n",
        "\n",
        "# Processing 'esai' for ca task\n",
        "train_sents_ca = []\n",
        "test_sents_ca = []\n",
        "\n",
        "for i in train_e_ca:\n",
        "    train_sents_ca += essay2word(i)\n",
        "\n",
        "for i in test_e_ca:\n",
        "    test_sents_ca += essay2word(i)\n",
        "\n",
        "# Processing 'esai' for gas task\n",
        "train_sents_gas = []\n",
        "test_sents_gas = []\n",
        "\n",
        "for i in train_e_gas:\n",
        "    train_sents_gas += essay2word(i)\n",
        "\n",
        "for i in test_e_gas:\n",
        "    test_sents_gas += essay2word(i)\n",
        "\n",
        "# Processing 'essay' for cor task\n",
        "train_sents_cor = []\n",
        "test_sents_cor = []\n",
        "\n",
        "for i in train_e_cor:\n",
        "    train_sents_cor += essay2word(i)\n",
        "\n",
        "for i in test_e_cor:\n",
        "    test_sents_cor += essay2word(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lISkVV7TFNIC"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=(1, 300), return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4, activation='relu'))  # Change this to match the number of your outputs (4 in this case)\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfTfNkSmFPhe",
        "outputId": "84e192c1-7e43-4b63-cae7-f6618de6b7ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-15205c414680>:17: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ],
      "source": [
        "# Training Word2Vec model\n",
        "num_features = 300\n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "model = Word2Vec(\n",
        "    train_sents_sao + train_sents_ca + train_sents_gas + train_sents_cor,\n",
        "    workers=num_workers,\n",
        "    vector_size=num_features,\n",
        "    min_count=min_word_count,\n",
        "    window=context,\n",
        "    sample=downsampling\n",
        ")\n",
        "\n",
        "model.init_sims(replace=True)\n",
        "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RjLZZlXKFRhp"
      },
      "outputs": [],
      "source": [
        "def makeVec(words, model, num_features):\n",
        "    vec = np.zeros((num_features,), dtype=\"float32\")\n",
        "    noOfWords = 0.\n",
        "    index_to_key_set = set(model.wv.index_to_key)\n",
        "    for i in words:\n",
        "        if i in index_to_key_set:\n",
        "            noOfWords += 1\n",
        "            vec = np.add(vec, model.wv[i])  # Use model.wv[i] instead of model[i]\n",
        "    vec = np.divide(vec, noOfWords)\n",
        "    return vec\n",
        "\n",
        "def getVecs(essays, model, num_features):\n",
        "    c = 0\n",
        "    essay_vecs = np.zeros((len(essays), num_features), dtype=\"float32\")\n",
        "    for i in essays:\n",
        "        essay_vecs[c] = makeVec(i, model, num_features)\n",
        "        c += 1\n",
        "    return essay_vecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aAfFx2ARY7gf"
      },
      "outputs": [],
      "source": [
        "# For sao task\n",
        "clean_train_sao = []\n",
        "for i in train_e_sao:\n",
        "    clean_train_sao.append(sent2word(i))\n",
        "training_vectors_sao = getVecs(clean_train_sao, model, num_features)\n",
        "\n",
        "clean_test_sao = []\n",
        "for i in test_e_sao:\n",
        "    clean_test_sao.append(sent2word(i))\n",
        "testing_vectors_sao = getVecs(clean_test_sao, model, num_features)\n",
        "\n",
        "# For ca task\n",
        "clean_train_ca = []\n",
        "for i in train_e_ca:\n",
        "    clean_train_ca.append(sent2word(i))\n",
        "training_vectors_ca = getVecs(clean_train_ca, model, num_features)\n",
        "\n",
        "clean_test_ca = []\n",
        "for i in test_e_ca:\n",
        "    clean_test_ca.append(sent2word(i))\n",
        "testing_vectors_ca = getVecs(clean_test_ca, model, num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKbiRO8GZHp0",
        "outputId": "03f7d011-0354-4993-ea24-3701ab212ddb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-4dc0d5092797>:9: RuntimeWarning: invalid value encountered in divide\n",
            "  vec = np.divide(vec, noOfWords)\n"
          ]
        }
      ],
      "source": [
        "# For gas task\n",
        "clean_train_gas = []\n",
        "for i in train_e_gas:\n",
        "    clean_train_gas.append(sent2word(i))\n",
        "training_vectors_gas = getVecs(clean_train_gas, model, num_features)\n",
        "\n",
        "clean_test_gas = []\n",
        "for i in test_e_gas:\n",
        "    clean_test_gas.append(sent2word(i))\n",
        "testing_vectors_gas = getVecs(clean_test_gas, model, num_features)\n",
        "\n",
        "# For cor task\n",
        "clean_train_cor = []\n",
        "for i in train_e_cor:\n",
        "    clean_train_cor.append(sent2word(i))\n",
        "training_vectors_cor = getVecs(clean_train_cor, model, num_features)\n",
        "\n",
        "clean_test_cor = []\n",
        "for i in test_e_cor:\n",
        "    clean_test_cor.append(sent2word(i))\n",
        "testing_vectors_cor = getVecs(clean_test_cor, model, num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4T1ZecLYZp1_"
      },
      "outputs": [],
      "source": [
        "# Reshaping vectors for sao task\n",
        "training_vectors_sao = np.array(training_vectors_sao)\n",
        "testing_vectors_sao = np.array(testing_vectors_sao)\n",
        "\n",
        "training_vectors_sao = np.reshape(training_vectors_sao, (training_vectors_sao.shape[0], 1, training_vectors_sao.shape[1]))\n",
        "testing_vectors_sao = np.reshape(testing_vectors_sao, (testing_vectors_sao.shape[0], 1, testing_vectors_sao.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qrdZEcSLagSw"
      },
      "outputs": [],
      "source": [
        "# Reshaping vectors for ca task\n",
        "training_vectors_ca = np.array(training_vectors_ca)\n",
        "testing_vectors_ca = np.array(testing_vectors_ca)\n",
        "\n",
        "training_vectors_ca = np.reshape(training_vectors_ca, (training_vectors_ca.shape[0], 1, training_vectors_ca.shape[1]))\n",
        "testing_vectors_ca = np.reshape(testing_vectors_ca, (testing_vectors_ca.shape[0], 1, testing_vectors_ca.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "j0rRo2CTajkJ"
      },
      "outputs": [],
      "source": [
        "training_vectors_gas = np.array(training_vectors_gas)\n",
        "testing_vectors_gas = np.array(testing_vectors_gas)\n",
        "\n",
        "training_vectors_gas = np.reshape(training_vectors_gas, (training_vectors_gas.shape[0], 1, training_vectors_gas.shape[1]))\n",
        "testing_vectors_gas = np.reshape(testing_vectors_gas, (testing_vectors_gas.shape[0], 1, testing_vectors_gas.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TNKzj3Ptalyv"
      },
      "outputs": [],
      "source": [
        "# Reshaping vectors for cor task\n",
        "training_vectors_cor = np.array(training_vectors_cor)\n",
        "testing_vectors_cor = np.array(testing_vectors_cor)\n",
        "\n",
        "training_vectors_cor = np.reshape(training_vectors_cor, (training_vectors_cor.shape[0], 1, training_vectors_cor.shape[1]))\n",
        "testing_vectors_cor = np.reshape(testing_vectors_cor, (testing_vectors_cor.shape[0], 1, testing_vectors_cor.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3l2nh9h2bmbO"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "def get_multi_model():\n",
        "    input_sao = Input(shape=(1, 300))\n",
        "    input_ca = Input(shape=(1, 300))\n",
        "    input_gas = Input(shape=(1, 300))\n",
        "    input_cor = Input(shape=(1, 300))\n",
        "\n",
        "    lstm_shared = LSTM(300, dropout=0.4, recurrent_dropout=0.4, return_sequences=True)\n",
        "\n",
        "    lstm_sao = lstm_shared(input_sao)\n",
        "    lstm_ca = lstm_shared(input_ca)\n",
        "    lstm_gas = lstm_shared(input_gas)\n",
        "    lstm_cor = lstm_shared(input_cor)\n",
        "\n",
        "    merged = Concatenate(axis=-1)([lstm_sao, lstm_ca, lstm_gas, lstm_cor])\n",
        "\n",
        "    lstm_final = LSTM(64, recurrent_dropout=0.4)(merged)\n",
        "    dropout = Dropout(0.5)(lstm_final)\n",
        "\n",
        "    # Adjust the number of units in the Dense layers based on your specific requirements\n",
        "    output_sao = Dense(1, activation='relu', name='output_sao')(dropout)\n",
        "    output_ca = Dense(1, activation='relu', name='output_ca')(dropout)\n",
        "    output_gas = Dense(1, activation='relu', name='output_gas')(dropout)\n",
        "    output_cor = Dense(1, activation='relu', name='output_cor')(dropout)\n",
        "\n",
        "    model = Model(inputs=[input_sao, input_ca, input_gas, input_cor], outputs=[output_sao, output_ca, output_gas, output_cor])\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dxAsJQ-a51b",
        "outputId": "920013a1-0ba4-4f7b-8d8a-c7d56064c223"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1, 300)]             0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 1, 300)]             0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 1, 300)]             0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 1, 300)]             0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 1, 300)               721200    ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]',             \n",
            "                                                                     'input_3[0][0]',             \n",
            "                                                                     'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1, 1200)              0         ['lstm[0][0]',                \n",
            "                                                                     'lstm[1][0]',                \n",
            "                                                                     'lstm[2][0]',                \n",
            "                                                                     'lstm[3][0]']                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 64)                   323840    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 64)                   0         ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " output_sao (Dense)          (None, 1)                    65        ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " output_ca (Dense)           (None, 1)                    65        ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " output_gas (Dense)          (None, 1)                    65        ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " output_cor (Dense)          (None, 1)                    65        ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1045300 (3.99 MB)\n",
            "Trainable params: 1045300 (3.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_model = get_multi_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yTlmcPbcDH6",
        "outputId": "dc412db6-7408-4201-e9e8-fa59985a21dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "142/142 [==============================] - 20s 30ms/step - loss: 39287.1094 - output_sao_loss: 3.3859 - output_ca_loss: 39266.8438 - output_gas_loss: 2.7692 - output_cor_loss: 14.1157 - output_sao_mae: 1.5124 - output_ca_mae: 150.4232 - output_gas_mae: 1.3551 - output_cor_mae: 3.0263\n",
            "Epoch 2/150\n",
            "142/142 [==============================] - 4s 29ms/step - loss: 36939.0586 - output_sao_loss: 2.0356 - output_ca_loss: 36927.7969 - output_gas_loss: 1.7812 - output_cor_loss: 7.4302 - output_sao_mae: 1.1753 - output_ca_mae: 142.5303 - output_gas_mae: 1.1121 - output_cor_mae: 2.2136\n",
            "Epoch 3/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 35027.9453 - output_sao_loss: 1.6960 - output_ca_loss: 35017.5156 - output_gas_loss: 1.5620 - output_cor_loss: 7.1674 - output_sao_mae: 1.0945 - output_ca_mae: 136.1405 - output_gas_mae: 1.0618 - output_cor_mae: 2.1676\n",
            "Epoch 4/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 33233.3281 - output_sao_loss: 1.4843 - output_ca_loss: 33223.3711 - output_gas_loss: 1.4403 - output_cor_loss: 7.0277 - output_sao_mae: 1.0375 - output_ca_mae: 130.0473 - output_gas_mae: 1.0348 - output_cor_mae: 2.1499\n",
            "Epoch 5/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 31483.5566 - output_sao_loss: 1.4067 - output_ca_loss: 31473.9492 - output_gas_loss: 1.3797 - output_cor_loss: 6.8359 - output_sao_mae: 1.0237 - output_ca_mae: 124.1864 - output_gas_mae: 1.0171 - output_cor_mae: 2.1165\n",
            "Epoch 6/150\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 29896.6953 - output_sao_loss: 1.3677 - output_ca_loss: 29887.2363 - output_gas_loss: 1.3558 - output_cor_loss: 6.7279 - output_sao_mae: 1.0143 - output_ca_mae: 118.9156 - output_gas_mae: 1.0115 - output_cor_mae: 2.1042\n",
            "Epoch 7/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 28430.5957 - output_sao_loss: 1.3595 - output_ca_loss: 28421.1152 - output_gas_loss: 1.3486 - output_cor_loss: 6.7831 - output_sao_mae: 1.0130 - output_ca_mae: 114.1854 - output_gas_mae: 1.0098 - output_cor_mae: 2.1099\n",
            "Epoch 8/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 26978.3398 - output_sao_loss: 1.3570 - output_ca_loss: 26968.9941 - output_gas_loss: 1.3470 - output_cor_loss: 6.6445 - output_sao_mae: 1.0141 - output_ca_mae: 109.8808 - output_gas_mae: 1.0122 - output_cor_mae: 2.0874\n",
            "Epoch 9/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 25652.8262 - output_sao_loss: 1.3411 - output_ca_loss: 25643.5586 - output_gas_loss: 1.3443 - output_cor_loss: 6.5779 - output_sao_mae: 1.0083 - output_ca_mae: 106.2177 - output_gas_mae: 1.0112 - output_cor_mae: 2.0774\n",
            "Epoch 10/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 24460.4141 - output_sao_loss: 1.3408 - output_ca_loss: 24451.1426 - output_gas_loss: 1.3508 - output_cor_loss: 6.5844 - output_sao_mae: 1.0114 - output_ca_mae: 102.7902 - output_gas_mae: 1.0158 - output_cor_mae: 2.0844\n",
            "Epoch 11/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 23330.9551 - output_sao_loss: 1.3388 - output_ca_loss: 23321.6836 - output_gas_loss: 1.3443 - output_cor_loss: 6.5879 - output_sao_mae: 1.0093 - output_ca_mae: 100.0860 - output_gas_mae: 1.0121 - output_cor_mae: 2.0775\n",
            "Epoch 12/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 22281.2891 - output_sao_loss: 1.3354 - output_ca_loss: 22272.1211 - output_gas_loss: 1.3399 - output_cor_loss: 6.4938 - output_sao_mae: 1.0068 - output_ca_mae: 97.7551 - output_gas_mae: 1.0121 - output_cor_mae: 2.0639\n",
            "Epoch 13/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 21409.0820 - output_sao_loss: 1.3361 - output_ca_loss: 21399.8320 - output_gas_loss: 1.3424 - output_cor_loss: 6.5761 - output_sao_mae: 1.0079 - output_ca_mae: 96.2268 - output_gas_mae: 1.0111 - output_cor_mae: 2.0740\n",
            "Epoch 14/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 20559.6562 - output_sao_loss: 1.3312 - output_ca_loss: 20550.4570 - output_gas_loss: 1.3363 - output_cor_loss: 6.5302 - output_sao_mae: 1.0068 - output_ca_mae: 94.7269 - output_gas_mae: 1.0123 - output_cor_mae: 2.0654\n",
            "Epoch 15/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 19815.8750 - output_sao_loss: 1.3306 - output_ca_loss: 19806.6875 - output_gas_loss: 1.3320 - output_cor_loss: 6.5185 - output_sao_mae: 1.0093 - output_ca_mae: 94.0102 - output_gas_mae: 1.0106 - output_cor_mae: 2.0679\n",
            "Epoch 16/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 19217.6758 - output_sao_loss: 1.3315 - output_ca_loss: 19208.4180 - output_gas_loss: 1.3380 - output_cor_loss: 6.5873 - output_sao_mae: 1.0124 - output_ca_mae: 93.8655 - output_gas_mae: 1.0108 - output_cor_mae: 2.0786\n",
            "Epoch 17/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 18634.4492 - output_sao_loss: 1.3248 - output_ca_loss: 18625.2969 - output_gas_loss: 1.3289 - output_cor_loss: 6.4937 - output_sao_mae: 1.0079 - output_ca_mae: 93.7262 - output_gas_mae: 1.0073 - output_cor_mae: 2.0613\n",
            "Epoch 18/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 18239.3516 - output_sao_loss: 1.3255 - output_ca_loss: 18230.1797 - output_gas_loss: 1.3337 - output_cor_loss: 6.5143 - output_sao_mae: 1.0084 - output_ca_mae: 94.0147 - output_gas_mae: 1.0114 - output_cor_mae: 2.0662\n",
            "Epoch 19/150\n",
            "142/142 [==============================] - 4s 31ms/step - loss: 17860.8496 - output_sao_loss: 1.3214 - output_ca_loss: 17851.7188 - output_gas_loss: 1.3324 - output_cor_loss: 6.4793 - output_sao_mae: 1.0064 - output_ca_mae: 94.5028 - output_gas_mae: 1.0126 - output_cor_mae: 2.0599\n",
            "Epoch 20/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 16353.7109 - output_sao_loss: 0.9806 - output_ca_loss: 16343.1875 - output_gas_loss: 1.8508 - output_cor_loss: 7.6897 - output_sao_mae: 0.8404 - output_ca_mae: 84.3881 - output_gas_mae: 1.1708 - output_cor_mae: 2.1988\n",
            "Epoch 21/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 15496.7842 - output_sao_loss: 0.8718 - output_ca_loss: 15486.4531 - output_gas_loss: 1.5732 - output_cor_loss: 7.8874 - output_sao_mae: 0.7760 - output_ca_mae: 81.2899 - output_gas_mae: 1.0709 - output_cor_mae: 2.2335\n",
            "Epoch 22/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 14692.8701 - output_sao_loss: 0.7936 - output_ca_loss: 14683.3760 - output_gas_loss: 1.2739 - output_cor_loss: 7.4281 - output_sao_mae: 0.7320 - output_ca_mae: 78.5933 - output_gas_mae: 0.9444 - output_cor_mae: 2.1939\n",
            "Epoch 23/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 14002.2686 - output_sao_loss: 0.7297 - output_ca_loss: 13993.0830 - output_gas_loss: 1.2986 - output_cor_loss: 7.1569 - output_sao_mae: 0.6989 - output_ca_mae: 76.2002 - output_gas_mae: 0.9489 - output_cor_mae: 2.1569\n",
            "Epoch 24/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 13345.3916 - output_sao_loss: 0.6618 - output_ca_loss: 13336.2871 - output_gas_loss: 1.2463 - output_cor_loss: 7.2010 - output_sao_mae: 0.6556 - output_ca_mae: 73.5909 - output_gas_mae: 0.9295 - output_cor_mae: 2.1667\n",
            "Epoch 25/150\n",
            "142/142 [==============================] - 6s 45ms/step - loss: 12599.9531 - output_sao_loss: 0.6075 - output_ca_loss: 12590.9355 - output_gas_loss: 1.2072 - output_cor_loss: 7.2029 - output_sao_mae: 0.6258 - output_ca_mae: 71.2133 - output_gas_mae: 0.9128 - output_cor_mae: 2.1629\n",
            "Epoch 26/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 12140.3408 - output_sao_loss: 0.5950 - output_ca_loss: 12131.3740 - output_gas_loss: 1.1775 - output_cor_loss: 7.1932 - output_sao_mae: 0.6222 - output_ca_mae: 69.9279 - output_gas_mae: 0.9029 - output_cor_mae: 2.1606\n",
            "Epoch 27/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 11572.4238 - output_sao_loss: 0.5784 - output_ca_loss: 11563.5342 - output_gas_loss: 1.1571 - output_cor_loss: 7.1513 - output_sao_mae: 0.6079 - output_ca_mae: 68.2382 - output_gas_mae: 0.8949 - output_cor_mae: 2.1509\n",
            "Epoch 28/150\n",
            "142/142 [==============================] - 4s 29ms/step - loss: 11097.5322 - output_sao_loss: 0.5631 - output_ca_loss: 11088.7148 - output_gas_loss: 1.1423 - output_cor_loss: 7.1148 - output_sao_mae: 0.6020 - output_ca_mae: 66.5490 - output_gas_mae: 0.8893 - output_cor_mae: 2.1518\n",
            "Epoch 29/150\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 10677.2168 - output_sao_loss: 0.5495 - output_ca_loss: 10668.4873 - output_gas_loss: 1.1195 - output_cor_loss: 7.0608 - output_sao_mae: 0.5966 - output_ca_mae: 65.2336 - output_gas_mae: 0.8798 - output_cor_mae: 2.1445\n",
            "Epoch 30/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 10068.5293 - output_sao_loss: 0.5344 - output_ca_loss: 10059.9102 - output_gas_loss: 1.1018 - output_cor_loss: 6.9842 - output_sao_mae: 0.5877 - output_ca_mae: 63.4878 - output_gas_mae: 0.8731 - output_cor_mae: 2.1336\n",
            "Epoch 31/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 9873.1836 - output_sao_loss: 0.5526 - output_ca_loss: 9864.4805 - output_gas_loss: 1.0724 - output_cor_loss: 7.0777 - output_sao_mae: 0.5962 - output_ca_mae: 62.9384 - output_gas_mae: 0.8632 - output_cor_mae: 2.1497\n",
            "Epoch 32/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 9458.4902 - output_sao_loss: 0.5381 - output_ca_loss: 9449.8555 - output_gas_loss: 1.0672 - output_cor_loss: 7.0278 - output_sao_mae: 0.5910 - output_ca_mae: 61.8214 - output_gas_mae: 0.8616 - output_cor_mae: 2.1409\n",
            "Epoch 33/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 9033.5186 - output_sao_loss: 0.5282 - output_ca_loss: 9024.9619 - output_gas_loss: 1.0473 - output_cor_loss: 6.9793 - output_sao_mae: 0.5840 - output_ca_mae: 60.3244 - output_gas_mae: 0.8557 - output_cor_mae: 2.1330\n",
            "Epoch 34/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 8836.7969 - output_sao_loss: 0.5396 - output_ca_loss: 8828.1855 - output_gas_loss: 1.0468 - output_cor_loss: 7.0249 - output_sao_mae: 0.5905 - output_ca_mae: 59.8570 - output_gas_mae: 0.8546 - output_cor_mae: 2.1461\n",
            "Epoch 35/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 8532.4268 - output_sao_loss: 0.5252 - output_ca_loss: 8523.8926 - output_gas_loss: 1.0042 - output_cor_loss: 7.0027 - output_sao_mae: 0.5830 - output_ca_mae: 58.9742 - output_gas_mae: 0.8390 - output_cor_mae: 2.1339\n",
            "Epoch 36/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 8285.0645 - output_sao_loss: 0.5224 - output_ca_loss: 8276.6553 - output_gas_loss: 1.0041 - output_cor_loss: 6.8793 - output_sao_mae: 0.5839 - output_ca_mae: 58.0522 - output_gas_mae: 0.8387 - output_cor_mae: 2.1215\n",
            "Epoch 37/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 8102.1709 - output_sao_loss: 0.5231 - output_ca_loss: 8093.7075 - output_gas_loss: 0.9979 - output_cor_loss: 6.9429 - output_sao_mae: 0.5840 - output_ca_mae: 57.7178 - output_gas_mae: 0.8363 - output_cor_mae: 2.1304\n",
            "Epoch 38/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 7882.4717 - output_sao_loss: 0.5127 - output_ca_loss: 7874.0361 - output_gas_loss: 0.9806 - output_cor_loss: 6.9469 - output_sao_mae: 0.5766 - output_ca_mae: 56.6166 - output_gas_mae: 0.8298 - output_cor_mae: 2.1311\n",
            "Epoch 39/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 7651.3838 - output_sao_loss: 0.5129 - output_ca_loss: 7643.0029 - output_gas_loss: 0.9423 - output_cor_loss: 6.9221 - output_sao_mae: 0.5825 - output_ca_mae: 56.5687 - output_gas_mae: 0.8140 - output_cor_mae: 2.1303\n",
            "Epoch 40/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 7560.2202 - output_sao_loss: 0.5055 - output_ca_loss: 7551.9375 - output_gas_loss: 0.9337 - output_cor_loss: 6.8418 - output_sao_mae: 0.5754 - output_ca_mae: 56.1633 - output_gas_mae: 0.8131 - output_cor_mae: 2.1122\n",
            "Epoch 41/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 7379.8105 - output_sao_loss: 0.5068 - output_ca_loss: 7371.4785 - output_gas_loss: 0.9221 - output_cor_loss: 6.9040 - output_sao_mae: 0.5773 - output_ca_mae: 55.7164 - output_gas_mae: 0.8023 - output_cor_mae: 2.1306\n",
            "Epoch 42/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 7235.7856 - output_sao_loss: 0.5085 - output_ca_loss: 7227.5146 - output_gas_loss: 0.9006 - output_cor_loss: 6.8612 - output_sao_mae: 0.5773 - output_ca_mae: 55.3549 - output_gas_mae: 0.7972 - output_cor_mae: 2.1264\n",
            "Epoch 43/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 7192.4263 - output_sao_loss: 0.5082 - output_ca_loss: 7184.2188 - output_gas_loss: 0.9012 - output_cor_loss: 6.8019 - output_sao_mae: 0.5769 - output_ca_mae: 55.0691 - output_gas_mae: 0.7943 - output_cor_mae: 2.1133\n",
            "Epoch 44/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 7073.2983 - output_sao_loss: 0.5050 - output_ca_loss: 7065.1421 - output_gas_loss: 0.8830 - output_cor_loss: 6.7680 - output_sao_mae: 0.5783 - output_ca_mae: 54.9165 - output_gas_mae: 0.7854 - output_cor_mae: 2.1121\n",
            "Epoch 45/150\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 6870.8774 - output_sao_loss: 0.4985 - output_ca_loss: 6862.7417 - output_gas_loss: 0.8599 - output_cor_loss: 6.7765 - output_sao_mae: 0.5714 - output_ca_mae: 54.1941 - output_gas_mae: 0.7750 - output_cor_mae: 2.1092\n",
            "Epoch 46/150\n",
            "142/142 [==============================] - 4s 29ms/step - loss: 6719.4263 - output_sao_loss: 0.4988 - output_ca_loss: 6711.3862 - output_gas_loss: 0.8558 - output_cor_loss: 6.6844 - output_sao_mae: 0.5723 - output_ca_mae: 53.8400 - output_gas_mae: 0.7692 - output_cor_mae: 2.0976\n",
            "Epoch 47/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6743.8696 - output_sao_loss: 0.4988 - output_ca_loss: 6735.8047 - output_gas_loss: 0.8508 - output_cor_loss: 6.7145 - output_sao_mae: 0.5745 - output_ca_mae: 54.0040 - output_gas_mae: 0.7731 - output_cor_mae: 2.1091\n",
            "Epoch 48/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6699.7695 - output_sao_loss: 0.5012 - output_ca_loss: 6691.7808 - output_gas_loss: 0.8372 - output_cor_loss: 6.6504 - output_sao_mae: 0.5738 - output_ca_mae: 54.0031 - output_gas_mae: 0.7632 - output_cor_mae: 2.0958\n",
            "Epoch 49/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 6549.3281 - output_sao_loss: 0.5031 - output_ca_loss: 6541.4067 - output_gas_loss: 0.8318 - output_cor_loss: 6.5855 - output_sao_mae: 0.5751 - output_ca_mae: 53.6210 - output_gas_mae: 0.7583 - output_cor_mae: 2.0873\n",
            "Epoch 50/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 6464.9224 - output_sao_loss: 0.4986 - output_ca_loss: 6456.9346 - output_gas_loss: 0.8374 - output_cor_loss: 6.6512 - output_sao_mae: 0.5729 - output_ca_mae: 53.2227 - output_gas_mae: 0.7620 - output_cor_mae: 2.0974\n",
            "Epoch 51/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6429.9175 - output_sao_loss: 0.5005 - output_ca_loss: 6422.0737 - output_gas_loss: 0.8205 - output_cor_loss: 6.5223 - output_sao_mae: 0.5740 - output_ca_mae: 53.1259 - output_gas_mae: 0.7530 - output_cor_mae: 2.0773\n",
            "Epoch 52/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 6358.8525 - output_sao_loss: 0.4966 - output_ca_loss: 6351.0137 - output_gas_loss: 0.8128 - output_cor_loss: 6.5296 - output_sao_mae: 0.5739 - output_ca_mae: 53.1059 - output_gas_mae: 0.7508 - output_cor_mae: 2.0795\n",
            "Epoch 53/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6282.9731 - output_sao_loss: 0.4967 - output_ca_loss: 6275.1567 - output_gas_loss: 0.8055 - output_cor_loss: 6.5123 - output_sao_mae: 0.5733 - output_ca_mae: 52.5503 - output_gas_mae: 0.7448 - output_cor_mae: 2.0746\n",
            "Epoch 54/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6290.8208 - output_sao_loss: 0.4945 - output_ca_loss: 6283.0977 - output_gas_loss: 0.7966 - output_cor_loss: 6.4324 - output_sao_mae: 0.5733 - output_ca_mae: 52.5706 - output_gas_mae: 0.7389 - output_cor_mae: 2.0635\n",
            "Epoch 55/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 6302.1245 - output_sao_loss: 0.5031 - output_ca_loss: 6294.4121 - output_gas_loss: 0.7919 - output_cor_loss: 6.4185 - output_sao_mae: 0.5779 - output_ca_mae: 52.9322 - output_gas_mae: 0.7382 - output_cor_mae: 2.0698\n",
            "Epoch 56/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 6117.8271 - output_sao_loss: 0.4925 - output_ca_loss: 6110.1143 - output_gas_loss: 0.7879 - output_cor_loss: 6.4354 - output_sao_mae: 0.5705 - output_ca_mae: 51.9445 - output_gas_mae: 0.7339 - output_cor_mae: 2.0688\n",
            "Epoch 57/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6027.3672 - output_sao_loss: 0.4961 - output_ca_loss: 6019.7549 - output_gas_loss: 0.7847 - output_cor_loss: 6.3334 - output_sao_mae: 0.5733 - output_ca_mae: 52.2261 - output_gas_mae: 0.7309 - output_cor_mae: 2.0513\n",
            "Epoch 58/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 6040.5566 - output_sao_loss: 0.4873 - output_ca_loss: 6032.9634 - output_gas_loss: 0.7752 - output_cor_loss: 6.3314 - output_sao_mae: 0.5693 - output_ca_mae: 51.6612 - output_gas_mae: 0.7247 - output_cor_mae: 2.0521\n",
            "Epoch 59/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 5961.1987 - output_sao_loss: 0.4923 - output_ca_loss: 5953.6074 - output_gas_loss: 0.7781 - output_cor_loss: 6.3251 - output_sao_mae: 0.5703 - output_ca_mae: 51.3782 - output_gas_mae: 0.7287 - output_cor_mae: 2.0575\n",
            "Epoch 60/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 6002.4604 - output_sao_loss: 0.4983 - output_ca_loss: 5994.9233 - output_gas_loss: 0.7720 - output_cor_loss: 6.2688 - output_sao_mae: 0.5744 - output_ca_mae: 51.7997 - output_gas_mae: 0.7252 - output_cor_mae: 2.0462\n",
            "Epoch 61/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 5968.1172 - output_sao_loss: 0.4924 - output_ca_loss: 5960.6201 - output_gas_loss: 0.7625 - output_cor_loss: 6.2414 - output_sao_mae: 0.5720 - output_ca_mae: 51.7491 - output_gas_mae: 0.7174 - output_cor_mae: 2.0335\n",
            "Epoch 62/150\n",
            "142/142 [==============================] - 5s 32ms/step - loss: 5850.4072 - output_sao_loss: 0.4840 - output_ca_loss: 5842.8896 - output_gas_loss: 0.7654 - output_cor_loss: 6.2690 - output_sao_mae: 0.5670 - output_ca_mae: 50.9814 - output_gas_mae: 0.7188 - output_cor_mae: 2.0486\n",
            "Epoch 63/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 5805.5171 - output_sao_loss: 0.4895 - output_ca_loss: 5798.0278 - output_gas_loss: 0.7634 - output_cor_loss: 6.2355 - output_sao_mae: 0.5699 - output_ca_mae: 50.9289 - output_gas_mae: 0.7168 - output_cor_mae: 2.0409\n",
            "Epoch 64/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 5927.0156 - output_sao_loss: 0.4932 - output_ca_loss: 5919.5664 - output_gas_loss: 0.7674 - output_cor_loss: 6.1890 - output_sao_mae: 0.5749 - output_ca_mae: 51.4855 - output_gas_mae: 0.7219 - output_cor_mae: 2.0326\n",
            "Epoch 65/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 5687.2759 - output_sao_loss: 0.4909 - output_ca_loss: 5679.8911 - output_gas_loss: 0.7526 - output_cor_loss: 6.1410 - output_sao_mae: 0.5724 - output_ca_mae: 50.6860 - output_gas_mae: 0.7100 - output_cor_mae: 2.0243\n",
            "Epoch 66/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 5603.3423 - output_sao_loss: 0.4883 - output_ca_loss: 5595.9185 - output_gas_loss: 0.7632 - output_cor_loss: 6.1741 - output_sao_mae: 0.5689 - output_ca_mae: 50.5586 - output_gas_mae: 0.7176 - output_cor_mae: 2.0339\n",
            "Epoch 67/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 5777.8149 - output_sao_loss: 0.4960 - output_ca_loss: 5770.4160 - output_gas_loss: 0.7651 - output_cor_loss: 6.1360 - output_sao_mae: 0.5745 - output_ca_mae: 51.1780 - output_gas_mae: 0.7183 - output_cor_mae: 2.0252\n",
            "Epoch 68/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 5641.0464 - output_sao_loss: 0.4920 - output_ca_loss: 5633.6641 - output_gas_loss: 0.7621 - output_cor_loss: 6.1294 - output_sao_mae: 0.5733 - output_ca_mae: 50.6562 - output_gas_mae: 0.7164 - output_cor_mae: 2.0236\n",
            "Epoch 69/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 5667.9404 - output_sao_loss: 0.4945 - output_ca_loss: 5660.5640 - output_gas_loss: 0.7688 - output_cor_loss: 6.1139 - output_sao_mae: 0.5753 - output_ca_mae: 50.8825 - output_gas_mae: 0.7186 - output_cor_mae: 2.0217\n",
            "Epoch 70/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5563.6997 - output_sao_loss: 0.4875 - output_ca_loss: 5556.3691 - output_gas_loss: 0.7557 - output_cor_loss: 6.0863 - output_sao_mae: 0.5709 - output_ca_mae: 50.4269 - output_gas_mae: 0.7123 - output_cor_mae: 2.0183\n",
            "Epoch 71/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5474.5908 - output_sao_loss: 0.4875 - output_ca_loss: 5467.2749 - output_gas_loss: 0.7483 - output_cor_loss: 6.0807 - output_sao_mae: 0.5719 - output_ca_mae: 49.8939 - output_gas_mae: 0.7098 - output_cor_mae: 2.0163\n",
            "Epoch 72/150\n",
            "142/142 [==============================] - 4s 32ms/step - loss: 5455.0283 - output_sao_loss: 0.4878 - output_ca_loss: 5447.7168 - output_gas_loss: 0.7526 - output_cor_loss: 6.0698 - output_sao_mae: 0.5714 - output_ca_mae: 50.1539 - output_gas_mae: 0.7097 - output_cor_mae: 2.0169\n",
            "Epoch 73/150\n",
            "142/142 [==============================] - 4s 28ms/step - loss: 5596.8477 - output_sao_loss: 0.4901 - output_ca_loss: 5589.5195 - output_gas_loss: 0.7591 - output_cor_loss: 6.0779 - output_sao_mae: 0.5723 - output_ca_mae: 50.1388 - output_gas_mae: 0.7125 - output_cor_mae: 2.0181\n",
            "Epoch 74/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5506.7783 - output_sao_loss: 0.4905 - output_ca_loss: 5499.5020 - output_gas_loss: 0.7476 - output_cor_loss: 6.0381 - output_sao_mae: 0.5728 - output_ca_mae: 50.1669 - output_gas_mae: 0.7081 - output_cor_mae: 2.0104\n",
            "Epoch 75/150\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 5391.7451 - output_sao_loss: 0.4815 - output_ca_loss: 5384.5181 - output_gas_loss: 0.7456 - output_cor_loss: 6.0009 - output_sao_mae: 0.5693 - output_ca_mae: 49.7407 - output_gas_mae: 0.7075 - output_cor_mae: 2.0022\n",
            "Epoch 76/150\n",
            "142/142 [==============================] - 5s 36ms/step - loss: 5372.9907 - output_sao_loss: 0.4840 - output_ca_loss: 5365.7202 - output_gas_loss: 0.7552 - output_cor_loss: 6.0290 - output_sao_mae: 0.5682 - output_ca_mae: 49.9446 - output_gas_mae: 0.7105 - output_cor_mae: 2.0089\n",
            "Epoch 77/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 5371.0786 - output_sao_loss: 0.4857 - output_ca_loss: 5363.8145 - output_gas_loss: 0.7480 - output_cor_loss: 6.0295 - output_sao_mae: 0.5734 - output_ca_mae: 49.7775 - output_gas_mae: 0.7071 - output_cor_mae: 2.0074\n",
            "Epoch 78/150\n",
            "142/142 [==============================] - 4s 28ms/step - loss: 5380.0278 - output_sao_loss: 0.4849 - output_ca_loss: 5372.7896 - output_gas_loss: 0.7526 - output_cor_loss: 6.0004 - output_sao_mae: 0.5725 - output_ca_mae: 49.7820 - output_gas_mae: 0.7128 - output_cor_mae: 2.0043\n",
            "Epoch 79/150\n",
            "142/142 [==============================] - 5s 38ms/step - loss: 5417.8745 - output_sao_loss: 0.4853 - output_ca_loss: 5410.6211 - output_gas_loss: 0.7562 - output_cor_loss: 6.0115 - output_sao_mae: 0.5717 - output_ca_mae: 50.0555 - output_gas_mae: 0.7134 - output_cor_mae: 2.0061\n",
            "Epoch 80/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 5246.9370 - output_sao_loss: 0.4801 - output_ca_loss: 5239.7041 - output_gas_loss: 0.7513 - output_cor_loss: 6.0025 - output_sao_mae: 0.5687 - output_ca_mae: 49.2980 - output_gas_mae: 0.7105 - output_cor_mae: 2.0002\n",
            "Epoch 81/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 5392.5767 - output_sao_loss: 0.4966 - output_ca_loss: 5385.3262 - output_gas_loss: 0.7536 - output_cor_loss: 6.0007 - output_sao_mae: 0.5772 - output_ca_mae: 49.8955 - output_gas_mae: 0.7117 - output_cor_mae: 2.0036\n",
            "Epoch 82/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 5313.0962 - output_sao_loss: 0.4832 - output_ca_loss: 5305.9009 - output_gas_loss: 0.7434 - output_cor_loss: 5.9645 - output_sao_mae: 0.5688 - output_ca_mae: 49.3455 - output_gas_mae: 0.7075 - output_cor_mae: 1.9991\n",
            "Epoch 83/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 5223.7612 - output_sao_loss: 0.4863 - output_ca_loss: 5216.5542 - output_gas_loss: 0.7495 - output_cor_loss: 5.9703 - output_sao_mae: 0.5706 - output_ca_mae: 49.0560 - output_gas_mae: 0.7065 - output_cor_mae: 1.9954\n",
            "Epoch 84/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 5342.1274 - output_sao_loss: 0.4903 - output_ca_loss: 5334.9297 - output_gas_loss: 0.7482 - output_cor_loss: 5.9600 - output_sao_mae: 0.5727 - output_ca_mae: 49.4952 - output_gas_mae: 0.7084 - output_cor_mae: 1.9907\n",
            "Epoch 85/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 5231.1509 - output_sao_loss: 0.4921 - output_ca_loss: 5223.9302 - output_gas_loss: 0.7538 - output_cor_loss: 5.9752 - output_sao_mae: 0.5761 - output_ca_mae: 49.3123 - output_gas_mae: 0.7105 - output_cor_mae: 2.0007\n",
            "Epoch 86/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5299.0381 - output_sao_loss: 0.4842 - output_ca_loss: 5291.8462 - output_gas_loss: 0.7471 - output_cor_loss: 5.9610 - output_sao_mae: 0.5718 - output_ca_mae: 49.4371 - output_gas_mae: 0.7092 - output_cor_mae: 1.9949\n",
            "Epoch 87/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5267.4888 - output_sao_loss: 0.4917 - output_ca_loss: 5260.2808 - output_gas_loss: 0.7551 - output_cor_loss: 5.9610 - output_sao_mae: 0.5765 - output_ca_mae: 49.3740 - output_gas_mae: 0.7127 - output_cor_mae: 1.9931\n",
            "Epoch 88/150\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 5229.0396 - output_sao_loss: 0.4925 - output_ca_loss: 5221.8560 - output_gas_loss: 0.7463 - output_cor_loss: 5.9480 - output_sao_mae: 0.5767 - output_ca_mae: 48.9091 - output_gas_mae: 0.7071 - output_cor_mae: 1.9906\n",
            "Epoch 89/150\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 5214.1245 - output_sao_loss: 0.4818 - output_ca_loss: 5206.9253 - output_gas_loss: 0.7460 - output_cor_loss: 5.9711 - output_sao_mae: 0.5692 - output_ca_mae: 49.1254 - output_gas_mae: 0.7091 - output_cor_mae: 1.9954\n",
            "Epoch 90/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5165.0903 - output_sao_loss: 0.4818 - output_ca_loss: 5157.8892 - output_gas_loss: 0.7430 - output_cor_loss: 5.9739 - output_sao_mae: 0.5705 - output_ca_mae: 48.8691 - output_gas_mae: 0.7059 - output_cor_mae: 1.9945\n",
            "Epoch 91/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 5136.3853 - output_sao_loss: 0.4863 - output_ca_loss: 5129.1973 - output_gas_loss: 0.7448 - output_cor_loss: 5.9570 - output_sao_mae: 0.5731 - output_ca_mae: 48.8012 - output_gas_mae: 0.7074 - output_cor_mae: 1.9934\n",
            "Epoch 92/150\n",
            "142/142 [==============================] - 5s 36ms/step - loss: 5116.7158 - output_sao_loss: 0.4808 - output_ca_loss: 5109.5259 - output_gas_loss: 0.7463 - output_cor_loss: 5.9606 - output_sao_mae: 0.5688 - output_ca_mae: 48.8316 - output_gas_mae: 0.7083 - output_cor_mae: 1.9947\n",
            "Epoch 93/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5091.1875 - output_sao_loss: 0.4843 - output_ca_loss: 5084.0283 - output_gas_loss: 0.7431 - output_cor_loss: 5.9330 - output_sao_mae: 0.5696 - output_ca_mae: 48.6125 - output_gas_mae: 0.7062 - output_cor_mae: 1.9862\n",
            "Epoch 94/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5133.7861 - output_sao_loss: 0.4829 - output_ca_loss: 5126.6064 - output_gas_loss: 0.7456 - output_cor_loss: 5.9517 - output_sao_mae: 0.5704 - output_ca_mae: 48.8585 - output_gas_mae: 0.7072 - output_cor_mae: 1.9920\n",
            "Epoch 95/150\n",
            "142/142 [==============================] - 5s 36ms/step - loss: 5029.7026 - output_sao_loss: 0.4861 - output_ca_loss: 5022.4990 - output_gas_loss: 0.7516 - output_cor_loss: 5.9658 - output_sao_mae: 0.5736 - output_ca_mae: 48.4340 - output_gas_mae: 0.7112 - output_cor_mae: 1.9949\n",
            "Epoch 96/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4927.0356 - output_sao_loss: 0.4808 - output_ca_loss: 4919.8584 - output_gas_loss: 0.7339 - output_cor_loss: 5.9616 - output_sao_mae: 0.5713 - output_ca_mae: 48.3712 - output_gas_mae: 0.7037 - output_cor_mae: 1.9936\n",
            "Epoch 97/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 5085.0522 - output_sao_loss: 0.4810 - output_ca_loss: 5077.8765 - output_gas_loss: 0.7415 - output_cor_loss: 5.9559 - output_sao_mae: 0.5705 - output_ca_mae: 48.4862 - output_gas_mae: 0.7066 - output_cor_mae: 1.9904\n",
            "Epoch 98/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 5107.7534 - output_sao_loss: 0.4821 - output_ca_loss: 5100.5757 - output_gas_loss: 0.7395 - output_cor_loss: 5.9561 - output_sao_mae: 0.5705 - output_ca_mae: 48.5456 - output_gas_mae: 0.7030 - output_cor_mae: 1.9905\n",
            "Epoch 99/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 5028.1274 - output_sao_loss: 0.4808 - output_ca_loss: 5020.9546 - output_gas_loss: 0.7363 - output_cor_loss: 5.9528 - output_sao_mae: 0.5709 - output_ca_mae: 48.2665 - output_gas_mae: 0.7035 - output_cor_mae: 1.9893\n",
            "Epoch 100/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 5068.7695 - output_sao_loss: 0.4798 - output_ca_loss: 5061.5786 - output_gas_loss: 0.7437 - output_cor_loss: 5.9661 - output_sao_mae: 0.5691 - output_ca_mae: 48.5352 - output_gas_mae: 0.7080 - output_cor_mae: 1.9945\n",
            "Epoch 101/150\n",
            "142/142 [==============================] - 4s 28ms/step - loss: 4981.6538 - output_sao_loss: 0.4740 - output_ca_loss: 4974.4927 - output_gas_loss: 0.7360 - output_cor_loss: 5.9527 - output_sao_mae: 0.5650 - output_ca_mae: 47.8418 - output_gas_mae: 0.7014 - output_cor_mae: 1.9908\n",
            "Epoch 102/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 5005.1035 - output_sao_loss: 0.4835 - output_ca_loss: 4997.9419 - output_gas_loss: 0.7406 - output_cor_loss: 5.9358 - output_sao_mae: 0.5713 - output_ca_mae: 48.1106 - output_gas_mae: 0.7063 - output_cor_mae: 1.9860\n",
            "Epoch 103/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4996.1123 - output_sao_loss: 0.4735 - output_ca_loss: 4988.9287 - output_gas_loss: 0.7417 - output_cor_loss: 5.9681 - output_sao_mae: 0.5643 - output_ca_mae: 47.8658 - output_gas_mae: 0.7040 - output_cor_mae: 1.9948\n",
            "Epoch 104/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4935.4800 - output_sao_loss: 0.4790 - output_ca_loss: 4928.2856 - output_gas_loss: 0.7410 - output_cor_loss: 5.9773 - output_sao_mae: 0.5682 - output_ca_mae: 47.8894 - output_gas_mae: 0.7055 - output_cor_mae: 1.9970\n",
            "Epoch 105/150\n",
            "142/142 [==============================] - 5s 36ms/step - loss: 4893.7378 - output_sao_loss: 0.4718 - output_ca_loss: 4886.5977 - output_gas_loss: 0.7388 - output_cor_loss: 5.9296 - output_sao_mae: 0.5662 - output_ca_mae: 47.3839 - output_gas_mae: 0.7062 - output_cor_mae: 1.9849\n",
            "Epoch 106/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4882.1152 - output_sao_loss: 0.4730 - output_ca_loss: 4874.9536 - output_gas_loss: 0.7314 - output_cor_loss: 5.9562 - output_sao_mae: 0.5658 - output_ca_mae: 47.6610 - output_gas_mae: 0.6996 - output_cor_mae: 1.9912\n",
            "Epoch 107/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4869.3413 - output_sao_loss: 0.4734 - output_ca_loss: 4862.1704 - output_gas_loss: 0.7407 - output_cor_loss: 5.9566 - output_sao_mae: 0.5666 - output_ca_mae: 47.8021 - output_gas_mae: 0.7059 - output_cor_mae: 1.9930\n",
            "Epoch 108/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 5001.8955 - output_sao_loss: 0.4776 - output_ca_loss: 4994.7207 - output_gas_loss: 0.7348 - output_cor_loss: 5.9625 - output_sao_mae: 0.5688 - output_ca_mae: 48.0598 - output_gas_mae: 0.7039 - output_cor_mae: 1.9923\n",
            "Epoch 109/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4890.2773 - output_sao_loss: 0.4794 - output_ca_loss: 4883.1055 - output_gas_loss: 0.7457 - output_cor_loss: 5.9477 - output_sao_mae: 0.5694 - output_ca_mae: 47.8952 - output_gas_mae: 0.7038 - output_cor_mae: 1.9901\n",
            "Epoch 110/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4954.1421 - output_sao_loss: 0.4776 - output_ca_loss: 4946.9668 - output_gas_loss: 0.7431 - output_cor_loss: 5.9547 - output_sao_mae: 0.5690 - output_ca_mae: 47.6355 - output_gas_mae: 0.7070 - output_cor_mae: 1.9909\n",
            "Epoch 111/150\n",
            "142/142 [==============================] - 4s 32ms/step - loss: 4871.4990 - output_sao_loss: 0.4761 - output_ca_loss: 4864.2920 - output_gas_loss: 0.7431 - output_cor_loss: 5.9873 - output_sao_mae: 0.5667 - output_ca_mae: 47.7789 - output_gas_mae: 0.7079 - output_cor_mae: 1.9985\n",
            "Epoch 112/150\n",
            "142/142 [==============================] - 4s 31ms/step - loss: 4950.4922 - output_sao_loss: 0.4769 - output_ca_loss: 4943.3359 - output_gas_loss: 0.7392 - output_cor_loss: 5.9421 - output_sao_mae: 0.5672 - output_ca_mae: 47.7682 - output_gas_mae: 0.7039 - output_cor_mae: 1.9871\n",
            "Epoch 113/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4907.2124 - output_sao_loss: 0.4730 - output_ca_loss: 4900.0674 - output_gas_loss: 0.7351 - output_cor_loss: 5.9360 - output_sao_mae: 0.5650 - output_ca_mae: 47.5042 - output_gas_mae: 0.7017 - output_cor_mae: 1.9917\n",
            "Epoch 114/150\n",
            "142/142 [==============================] - 4s 31ms/step - loss: 4822.9902 - output_sao_loss: 0.4704 - output_ca_loss: 4815.8315 - output_gas_loss: 0.7420 - output_cor_loss: 5.9458 - output_sao_mae: 0.5661 - output_ca_mae: 47.4740 - output_gas_mae: 0.7056 - output_cor_mae: 1.9902\n",
            "Epoch 115/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 4932.6694 - output_sao_loss: 0.4739 - output_ca_loss: 4925.5156 - output_gas_loss: 0.7430 - output_cor_loss: 5.9377 - output_sao_mae: 0.5665 - output_ca_mae: 47.7172 - output_gas_mae: 0.7077 - output_cor_mae: 1.9907\n",
            "Epoch 116/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4840.1606 - output_sao_loss: 0.4701 - output_ca_loss: 4833.0112 - output_gas_loss: 0.7378 - output_cor_loss: 5.9418 - output_sao_mae: 0.5642 - output_ca_mae: 47.5419 - output_gas_mae: 0.7061 - output_cor_mae: 1.9892\n",
            "Epoch 117/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4831.5835 - output_sao_loss: 0.4728 - output_ca_loss: 4824.4478 - output_gas_loss: 0.7313 - output_cor_loss: 5.9318 - output_sao_mae: 0.5658 - output_ca_mae: 47.4169 - output_gas_mae: 0.7020 - output_cor_mae: 1.9905\n",
            "Epoch 118/150\n",
            "142/142 [==============================] - 5s 35ms/step - loss: 4843.8613 - output_sao_loss: 0.4720 - output_ca_loss: 4836.7397 - output_gas_loss: 0.7404 - output_cor_loss: 5.9070 - output_sao_mae: 0.5662 - output_ca_mae: 47.6504 - output_gas_mae: 0.7076 - output_cor_mae: 1.9789\n",
            "Epoch 119/150\n",
            "142/142 [==============================] - 3s 25ms/step - loss: 4701.8057 - output_sao_loss: 0.4673 - output_ca_loss: 4694.6567 - output_gas_loss: 0.7285 - output_cor_loss: 5.9546 - output_sao_mae: 0.5633 - output_ca_mae: 46.8662 - output_gas_mae: 0.7002 - output_cor_mae: 1.9913\n",
            "Epoch 120/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4818.4580 - output_sao_loss: 0.4724 - output_ca_loss: 4811.2900 - output_gas_loss: 0.7392 - output_cor_loss: 5.9579 - output_sao_mae: 0.5636 - output_ca_mae: 46.9121 - output_gas_mae: 0.7053 - output_cor_mae: 1.9927\n",
            "Epoch 121/150\n",
            "142/142 [==============================] - 5s 36ms/step - loss: 4865.5835 - output_sao_loss: 0.4695 - output_ca_loss: 4858.4160 - output_gas_loss: 0.7324 - output_cor_loss: 5.9669 - output_sao_mae: 0.5643 - output_ca_mae: 47.3628 - output_gas_mae: 0.7015 - output_cor_mae: 1.9944\n",
            "Epoch 122/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4787.9512 - output_sao_loss: 0.4713 - output_ca_loss: 4780.7998 - output_gas_loss: 0.7351 - output_cor_loss: 5.9446 - output_sao_mae: 0.5659 - output_ca_mae: 47.1572 - output_gas_mae: 0.7026 - output_cor_mae: 1.9888\n",
            "Epoch 123/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4660.5767 - output_sao_loss: 0.4707 - output_ca_loss: 4653.4102 - output_gas_loss: 0.7374 - output_cor_loss: 5.9583 - output_sao_mae: 0.5645 - output_ca_mae: 46.8099 - output_gas_mae: 0.7075 - output_cor_mae: 1.9932\n",
            "Epoch 124/150\n",
            "142/142 [==============================] - 5s 38ms/step - loss: 4834.2900 - output_sao_loss: 0.4666 - output_ca_loss: 4827.1631 - output_gas_loss: 0.7231 - output_cor_loss: 5.9367 - output_sao_mae: 0.5605 - output_ca_mae: 47.3478 - output_gas_mae: 0.6994 - output_cor_mae: 1.9865\n",
            "Epoch 125/150\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 4817.6553 - output_sao_loss: 0.4732 - output_ca_loss: 4810.5190 - output_gas_loss: 0.7309 - output_cor_loss: 5.9309 - output_sao_mae: 0.5660 - output_ca_mae: 47.3274 - output_gas_mae: 0.7025 - output_cor_mae: 1.9873\n",
            "Epoch 126/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4814.7583 - output_sao_loss: 0.4691 - output_ca_loss: 4807.6230 - output_gas_loss: 0.7333 - output_cor_loss: 5.9356 - output_sao_mae: 0.5643 - output_ca_mae: 47.0368 - output_gas_mae: 0.7023 - output_cor_mae: 1.9889\n",
            "Epoch 127/150\n",
            "142/142 [==============================] - 5s 33ms/step - loss: 4771.3208 - output_sao_loss: 0.4680 - output_ca_loss: 4764.1704 - output_gas_loss: 0.7346 - output_cor_loss: 5.9469 - output_sao_mae: 0.5647 - output_ca_mae: 47.0442 - output_gas_mae: 0.7047 - output_cor_mae: 1.9899\n",
            "Epoch 128/150\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 4820.6724 - output_sao_loss: 0.4793 - output_ca_loss: 4813.5122 - output_gas_loss: 0.7399 - output_cor_loss: 5.9424 - output_sao_mae: 0.5714 - output_ca_mae: 47.2953 - output_gas_mae: 0.7064 - output_cor_mae: 1.9860\n",
            "Epoch 129/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4724.6992 - output_sao_loss: 0.4717 - output_ca_loss: 4717.5322 - output_gas_loss: 0.7352 - output_cor_loss: 5.9617 - output_sao_mae: 0.5659 - output_ca_mae: 47.2592 - output_gas_mae: 0.7030 - output_cor_mae: 1.9891\n",
            "Epoch 130/150\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 4725.2397 - output_sao_loss: 0.4682 - output_ca_loss: 4718.1211 - output_gas_loss: 0.7361 - output_cor_loss: 5.9139 - output_sao_mae: 0.5637 - output_ca_mae: 46.9085 - output_gas_mae: 0.7041 - output_cor_mae: 1.9848\n",
            "Epoch 131/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 4683.4580 - output_sao_loss: 0.4679 - output_ca_loss: 4676.3120 - output_gas_loss: 0.7385 - output_cor_loss: 5.9369 - output_sao_mae: 0.5643 - output_ca_mae: 46.5830 - output_gas_mae: 0.7072 - output_cor_mae: 1.9892\n",
            "Epoch 132/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4681.9370 - output_sao_loss: 0.4664 - output_ca_loss: 4674.7935 - output_gas_loss: 0.7333 - output_cor_loss: 5.9428 - output_sao_mae: 0.5635 - output_ca_mae: 46.5959 - output_gas_mae: 0.7052 - output_cor_mae: 1.9848\n",
            "Epoch 133/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4546.9990 - output_sao_loss: 0.4617 - output_ca_loss: 4539.8530 - output_gas_loss: 0.7358 - output_cor_loss: 5.9493 - output_sao_mae: 0.5606 - output_ca_mae: 46.0644 - output_gas_mae: 0.7044 - output_cor_mae: 1.9903\n",
            "Epoch 134/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 4805.0098 - output_sao_loss: 0.4676 - output_ca_loss: 4797.8794 - output_gas_loss: 0.7380 - output_cor_loss: 5.9267 - output_sao_mae: 0.5640 - output_ca_mae: 46.9274 - output_gas_mae: 0.7048 - output_cor_mae: 1.9895\n",
            "Epoch 135/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4645.1006 - output_sao_loss: 0.4689 - output_ca_loss: 4637.9785 - output_gas_loss: 0.7263 - output_cor_loss: 5.9262 - output_sao_mae: 0.5641 - output_ca_mae: 46.5800 - output_gas_mae: 0.6991 - output_cor_mae: 1.9857\n",
            "Epoch 136/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4757.9790 - output_sao_loss: 0.4677 - output_ca_loss: 4750.8457 - output_gas_loss: 0.7352 - output_cor_loss: 5.9301 - output_sao_mae: 0.5639 - output_ca_mae: 47.1242 - output_gas_mae: 0.7055 - output_cor_mae: 1.9872\n",
            "Epoch 137/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 4590.1592 - output_sao_loss: 0.4665 - output_ca_loss: 4583.0503 - output_gas_loss: 0.7216 - output_cor_loss: 5.9209 - output_sao_mae: 0.5636 - output_ca_mae: 46.1633 - output_gas_mae: 0.6972 - output_cor_mae: 1.9846\n",
            "Epoch 138/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4588.7969 - output_sao_loss: 0.4640 - output_ca_loss: 4581.6758 - output_gas_loss: 0.7362 - output_cor_loss: 5.9201 - output_sao_mae: 0.5596 - output_ca_mae: 46.2246 - output_gas_mae: 0.7059 - output_cor_mae: 1.9860\n",
            "Epoch 139/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4588.1108 - output_sao_loss: 0.4610 - output_ca_loss: 4580.9629 - output_gas_loss: 0.7338 - output_cor_loss: 5.9534 - output_sao_mae: 0.5582 - output_ca_mae: 45.9600 - output_gas_mae: 0.7036 - output_cor_mae: 1.9942\n",
            "Epoch 140/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 4657.2261 - output_sao_loss: 0.4677 - output_ca_loss: 4650.0591 - output_gas_loss: 0.7340 - output_cor_loss: 5.9680 - output_sao_mae: 0.5626 - output_ca_mae: 46.6082 - output_gas_mae: 0.7029 - output_cor_mae: 1.9946\n",
            "Epoch 141/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4612.6079 - output_sao_loss: 0.4636 - output_ca_loss: 4605.4482 - output_gas_loss: 0.7343 - output_cor_loss: 5.9636 - output_sao_mae: 0.5628 - output_ca_mae: 46.3892 - output_gas_mae: 0.7053 - output_cor_mae: 1.9938\n",
            "Epoch 142/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4662.6953 - output_sao_loss: 0.4662 - output_ca_loss: 4655.5527 - output_gas_loss: 0.7295 - output_cor_loss: 5.9476 - output_sao_mae: 0.5604 - output_ca_mae: 46.5700 - output_gas_mae: 0.7035 - output_cor_mae: 1.9885\n",
            "Epoch 143/150\n",
            "142/142 [==============================] - 5s 37ms/step - loss: 4577.3940 - output_sao_loss: 0.4584 - output_ca_loss: 4570.3003 - output_gas_loss: 0.7226 - output_cor_loss: 5.9127 - output_sao_mae: 0.5589 - output_ca_mae: 46.2388 - output_gas_mae: 0.6991 - output_cor_mae: 1.9802\n",
            "Epoch 144/150\n",
            "142/142 [==============================] - 4s 27ms/step - loss: 4546.4805 - output_sao_loss: 0.4639 - output_ca_loss: 4539.3716 - output_gas_loss: 0.7293 - output_cor_loss: 5.9173 - output_sao_mae: 0.5611 - output_ca_mae: 45.7533 - output_gas_mae: 0.7037 - output_cor_mae: 1.9842\n",
            "Epoch 145/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4619.8076 - output_sao_loss: 0.4678 - output_ca_loss: 4612.6851 - output_gas_loss: 0.7259 - output_cor_loss: 5.9291 - output_sao_mae: 0.5638 - output_ca_mae: 46.2698 - output_gas_mae: 0.6997 - output_cor_mae: 1.9889\n",
            "Epoch 146/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 4713.9380 - output_sao_loss: 0.4701 - output_ca_loss: 4706.8164 - output_gas_loss: 0.7265 - output_cor_loss: 5.9262 - output_sao_mae: 0.5652 - output_ca_mae: 46.5071 - output_gas_mae: 0.7029 - output_cor_mae: 1.9871\n",
            "Epoch 147/150\n",
            "142/142 [==============================] - 4s 29ms/step - loss: 4576.1787 - output_sao_loss: 0.4647 - output_ca_loss: 4569.0347 - output_gas_loss: 0.7313 - output_cor_loss: 5.9507 - output_sao_mae: 0.5633 - output_ca_mae: 46.1498 - output_gas_mae: 0.7041 - output_cor_mae: 1.9949\n",
            "Epoch 148/150\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 4573.5850 - output_sao_loss: 0.4576 - output_ca_loss: 4566.4458 - output_gas_loss: 0.7230 - output_cor_loss: 5.9597 - output_sao_mae: 0.5573 - output_ca_mae: 45.9206 - output_gas_mae: 0.6973 - output_cor_mae: 1.9922\n",
            "Epoch 149/150\n",
            "142/142 [==============================] - 4s 29ms/step - loss: 4680.1279 - output_sao_loss: 0.4661 - output_ca_loss: 4672.9629 - output_gas_loss: 0.7369 - output_cor_loss: 5.9590 - output_sao_mae: 0.5637 - output_ca_mae: 46.6322 - output_gas_mae: 0.7031 - output_cor_mae: 1.9921\n",
            "Epoch 150/150\n",
            "142/142 [==============================] - 5s 34ms/step - loss: 4611.3374 - output_sao_loss: 0.4618 - output_ca_loss: 4604.1973 - output_gas_loss: 0.7280 - output_cor_loss: 5.9489 - output_sao_mae: 0.5604 - output_ca_mae: 46.2496 - output_gas_mae: 0.7020 - output_cor_mae: 1.9862\n"
          ]
        }
      ],
      "source": [
        "lstm_model.fit([training_vectors_sao, training_vectors_ca, training_vectors_gas, training_vectors_cor],\n",
        "                            [y_sao_train, y_ca_train, y_gas_train, y_cor_train],\n",
        "                            batch_size=64, epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc7L9IrltBAV"
      },
      "outputs": [],
      "source": [
        "lstm_model.save('aes_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN6p055PFWup",
        "outputId": "6c7e3385-a6a0-403e-ece4-72e8946921c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter an essay to test the model: Surat kabar lokal yang terhormat, menurut saya pengaruh komputer terhadap manusia adalah keterampilan/pengaruh belajar yang hebat karena komputer memberi kita waktu untuk ngobrol dengan teman/orang baru, membantu kita belajar tentang dunia (astronomi) dan menjauhkan kita dari masalah! Pikirkan tentang! Bukankah begitu? Bagaimana perasaan Anda jika anak remaja Anda selalu menelepon teman-temannya! Pernahkah Anda ngobrol dengan teman atau mitra bisnis Anda tentang berbagai hal. Nah sekarang - ada cara baru untuk ngobrol di komputer, ada banyak situs di internet untuk melakukannya: @ ORGANIZATION1, @ ORGANIZATION2, @ CAPS1, facebook, myspace dll. Bayangkan saja saat Anda mengatur pertemuan dengan atasan Anda di komputer, anak remaja Anda sedang bersenang-senang di telepon dan tidak terburu-buru menutup telepon karena Anda ingin menggunakannya. Bagaimana Anda mengetahui tentang negara/negara bagian lain di luar negara Anda? Ya, saya menggunakan komputer/internet, ini adalah cara baru untuk mempelajari apa yang terjadi di zaman kita! Anda mungkin berpikir anak Anda menghabiskan banyak waktu di depan komputer, tapi tanyakan kepada mereka pertanyaan tentang perekonomian, penyebaran dasar laut atau bahkan tentang @ DATE1, Anda akan terkejut betapa banyak yang dia ketahui. Percaya atau tidak, komputer jauh lebih menarik daripada membaca buku sepanjang hari di kelas. Jika anak Anda ada di rumah menggunakan komputer atau di perpustakaan setempat, itu lebih baik daripada keluar bersama teman-temannya dalam keadaan segar, atau ditekan untuk melakukan sesuatu yang mereka tahu tidak benar. Anda mungkin tidak tahu di mana anak Anda berada, @ CAPS2 melarang di ranjang rumah sakit karena ada perjalanan. Daripada anak Anda belajar di depan komputer, mengobrol, atau sekadar bermain game, aman dan nyaman di rumah atau tempat komunitas Anda. Sekarang saya harap Anda telah mencapai titik untuk memahami dan setuju dengan saya, karena komputer dapat memberikan dampak yang besar pada Anda atau anak karena memberikan kita waktu untuk ngobrol dengan teman/orang baru, membantu kita belajar tentang dunia dan percaya atau tidak menjaga kita. keluar dari masalah. Terima kasih untuk mendengarkan.\n",
            "1/1 [==============================] - 1s 921ms/step\n",
            "Predicted scores:\n",
            "Task 1 (y_sao): [3.1348624]\n",
            "Task 2 (y_ca): [253.31671]\n",
            "Task 3 (y_gas): [2.4877753]\n",
            "Task 4 (y_cor): [5.778802]\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have already loaded the trained model (multi_input_lstm_model)\n",
        "# and the necessary preprocessing functions (sent2word, makeVec, etc.)\n",
        "\n",
        "# Input for testing\n",
        "user_input = input(\"Enter an essay to test the model: \")\n",
        "\n",
        "# Preprocess the user input\n",
        "user_input_words = sent2word(user_input)\n",
        "user_input_vec = makeVec(user_input_words, model, num_features)\n",
        "\n",
        "# Reshape the input vector to match the model input shape\n",
        "user_input_vec = np.reshape(user_input_vec, (1, 1, num_features))\n",
        "\n",
        "# Make predictions using the multi_input_lstm_model\n",
        "predicted_scores = lstm_model.predict([user_input_vec, user_input_vec, user_input_vec, user_input_vec])\n",
        "\n",
        "# Display the predicted scores\n",
        "print(\"Predicted scores:\")\n",
        "print(f\"Task 1 (y_sao): {predicted_scores[0][0]}\")\n",
        "print(f\"Task 2 (y_ca): {predicted_scores[1][0]}\")\n",
        "print(f\"Task 3 (y_gas): {predicted_scores[2][0]}\")\n",
        "print(f\"Task 4 (y_cor): {predicted_scores[3][0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tYCD5DVCfDpc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
